{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Technology - Martin RE\n",
    "\n",
    "The dataset contains `N = 441` firms observed over `T = 12` years, 1968-1979. There variables are: \n",
    "* `lcap`: Log of capital stock, $k_{it}$ \n",
    "* `lemp`: log of employment, $\\ell_{it}$ \n",
    "* `ldsa`: log of deflated sales, $y_{it}$\n",
    "* `year`: the calendar year of the observation, `year` $ = 1968, ..., 1979$, \n",
    "* `firmid`: anonymized indicator variable for the firm, $i = 1, ..., N$, with $N=441$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "from io import StringIO\n",
    "from tabulate import tabulate\n",
    "import LinearModelsWeek3 as lm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Supress Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv('firms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data to numpy format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firmid</th>\n",
       "      <th>year</th>\n",
       "      <th>lcap</th>\n",
       "      <th>lemp</th>\n",
       "      <th>ldsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.998602</td>\n",
       "      <td>-0.242185</td>\n",
       "      <td>0.349053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1969</td>\n",
       "      <td>0.925214</td>\n",
       "      <td>-0.241278</td>\n",
       "      <td>0.312492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.879616</td>\n",
       "      <td>-0.265134</td>\n",
       "      <td>0.347566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1968</td>\n",
       "      <td>-0.069588</td>\n",
       "      <td>-0.323021</td>\n",
       "      <td>-0.945831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1969</td>\n",
       "      <td>-0.056724</td>\n",
       "      <td>-0.358177</td>\n",
       "      <td>-1.143830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>440</td>\n",
       "      <td>1969</td>\n",
       "      <td>-0.228757</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>-0.246864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>440</td>\n",
       "      <td>1970</td>\n",
       "      <td>-0.038354</td>\n",
       "      <td>0.062158</td>\n",
       "      <td>-0.345710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>441</td>\n",
       "      <td>1968</td>\n",
       "      <td>-1.618390</td>\n",
       "      <td>-1.944210</td>\n",
       "      <td>-2.032340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>441</td>\n",
       "      <td>1969</td>\n",
       "      <td>-1.635030</td>\n",
       "      <td>-1.856580</td>\n",
       "      <td>-2.011210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>441</td>\n",
       "      <td>1970</td>\n",
       "      <td>-1.454890</td>\n",
       "      <td>-1.538940</td>\n",
       "      <td>-1.371550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1323 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      firmid  year      lcap      lemp      ldsa\n",
       "0          1  1968  0.998602 -0.242185  0.349053\n",
       "1          1  1969  0.925214 -0.241278  0.312492\n",
       "2          1  1970  0.879616 -0.265134  0.347566\n",
       "3          2  1968 -0.069588 -0.323021 -0.945831\n",
       "4          2  1969 -0.056724 -0.358177 -1.143830\n",
       "...      ...   ...       ...       ...       ...\n",
       "1318     440  1969 -0.228757  0.031242 -0.246864\n",
       "1319     440  1970 -0.038354  0.062158 -0.345710\n",
       "1320     441  1968 -1.618390 -1.944210 -2.032340\n",
       "1321     441  1969 -1.635030 -1.856580 -2.011210\n",
       "1322     441  1970 -1.454890 -1.538940 -1.371550\n",
       "\n",
       "[1323 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Beholder kun 3 år\n",
    "\n",
    "dat = dat[(dat['year'] >= 1968) & (dat['year'] <= 1970)]\n",
    "dat=dat.reset_index(drop=True)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1323,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.ldsa.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has N=441 and T=3\n"
     ]
    }
   ],
   "source": [
    "N = dat.firmid.unique().size\n",
    "T = dat.year.unique().size\n",
    "assert dat.shape[0] == N*T, f'Error: data is not a balanced panel'\n",
    "print(f'Data has N={N} and T={T}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from `pandas` to `numpy` arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1323, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dat.ldsa.values.reshape((N*T,1))\n",
    "\n",
    "#Should we not stack the ones on there as well for the constant? - What do we do with the constant in RE? \n",
    "\n",
    "\n",
    "ones = np.ones((N*T,1))\n",
    "l = dat.lemp.values.reshape((N*T,1))\n",
    "k = dat.lcap.values.reshape((N*T,1))\n",
    "x = np.hstack([l, k])\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE AND FD RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demeaning matrix for T=3 \n",
      " [[ 0.66666667 -0.33333333 -0.33333333]\n",
      " [-0.33333333  0.66666667 -0.33333333]\n",
      " [-0.33333333 -0.33333333  0.66666667]]\n",
      "(1323, 2)\n",
      "Rank of demeaned x: 2\n",
      "Eigenvalues of within-transformed x: [9. 5.]\n",
      "FE regression\n",
      "Dependent variable: log Deflated sales\n",
      "\n",
      "                              Beta      Se    t-values\n",
      "--------------------------  ------  ------  ----------\n",
      "log Employment              0.6004  0.0346     17.3515\n",
      "log Adjusted Capital Stock  0.0502  0.0382      1.3143\n",
      "R² = 0.284\n",
      "σ² = 0.008\n"
     ]
    }
   ],
   "source": [
    "# Create transformation matrix\n",
    "def demeaning_matrix(T):\n",
    "    ones_T = np.ones(T)\n",
    "    Q_T = np.identity(T) - (1 / T) * np.outer(ones_T, ones_T)\n",
    "    return Q_T\n",
    "\n",
    "# Print the matrix\n",
    "Q_T = demeaning_matrix(T)\n",
    "print(f'Demeaning matrix for T={T} \\n', Q_T)\n",
    "\n",
    "# Transform the data\n",
    "y_demean = lm.perm(Q_T, y)\n",
    "x_demean = lm.perm(Q_T, x)\n",
    "\n",
    "#print x_demean\n",
    "print(x_demean.shape)\n",
    "\n",
    "label_y = 'log Deflated sales'\n",
    "label_x = [\n",
    "    'log Employment', \n",
    "    'log Adjusted Capital Stock',  \n",
    "]\n",
    "# Create function to check rank of demeaned matrix, and return its eigenvalues.\n",
    "def check_rank(x):\n",
    "    print(f'Rank of demeaned x: {la.matrix_rank(x)}')\n",
    "    lambdas, V = la.eig(x.T@x)\n",
    "    np.set_printoptions(suppress=True)  # This is just to print nicely.\n",
    "    print(f'Eigenvalues of within-transformed x: {lambdas.round(decimals=0)}')\n",
    "\n",
    "# Check rank of demeaned x\n",
    "check_rank(x_demean)\n",
    "\n",
    "# Estimate using the demeaned variables, y_demean and x_demean\n",
    "fe_result = lm.estimate(y_demean, x_demean, transform='fe', T=T)\n",
    "\n",
    "# Print results\n",
    "lm.print_table((label_y, label_x), fe_result, title='FE regression', floatfmt='.4f')\n",
    "b_hat=fe_result['b_hat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random effects estimation\n",
    "Last time we briefly discussed how the presence of unobserved heterogeneity can cause estimators to be biased. Consider the following model,\n",
    "\n",
    "For RE, it must hold that: \n",
    "$E[c_i\\boldsymbol{x}_{it}]=0$ for all $t$, so $\\boldsymbol{\\beta}$ can be consistently estimated by pooled OLS (POLS) and random effects (RE) if the respective rank conditions hold. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some (time-invariant) variables that we could control for, for example if we believe afro americans are more or less prone to unionizing, because of some social economic factors. We can look at the conditional mean for Blacks and Hispanics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: The random effects (RE) estimator.\n",
    "In part 1 we used two methods to remove unobserved heterogeneity from each person. Now, what if $E[union_{it}c_i] = 0$? Then POLS is consistent, but not efficient, since POLS is not using the panel structure of the data. We can therefore do better with the RE estimator.\n",
    "\n",
    "## A short introduction to the RE estimator\n",
    "With the FE and FD estimators, we estimate them by OLS, but by first transforming them in a specific way. We can do the same for RE, but our mission is no longer to transform away the fixed effects, but rather to estimate the following model,\n",
    "\n",
    "$$\\check{y}_{it} = \\mathbf{\\check{x}}_{it}\\boldsymbol{\\beta} + \\check{v}_{it},\\tag{6}$$ \n",
    "\n",
    " $\\check{y}_{it} = y_{it} - \\hat{\\lambda}\\bar{y}_{it}$, $\\mathbf{\\check{x}}_{it} = \\mathbf{x}_{it} - \\hat{\\lambda}\\mathbf{\\bar{x}}_{it}$, and $\\check{v}_{it} = v_{it} - \\hat{\\lambda}\\bar{v}_{it}$, where we have gathered the errors $v_{it} = c_i + u_{it}$. We are *\"quasi-demeaning\"* the variables, by premultiplying the means by $\\hat{\\lambda}$ (see Wooldridge p. 326-328).\n",
    "\n",
    " Our challenge is thus to estimate this $\\lambda$, which we can construct in the following way:\n",
    "\n",
    "$$\\hat{\\lambda} = 1 - \\sqrt{\\frac{\\widehat{\\sigma}_{u}^{2}}{(\\widehat{\\sigma}_{u}^{2} + T\\widehat{\\sigma}_{c}^{2})}}, $$\n",
    "\n",
    "where $\\widehat{\\sigma}_{u}^{2}$ can be estimated from the fixed effects regression, and $\\hat{\\sigma}_{c}^{2}$ can be constructed as  $\\hat{\\sigma}_{c}^{2} = \\hat{\\sigma}_{w}^{2} - \\frac{1}{T}\\hat{\\sigma}_{u}^{2}$. Here $\\hat{\\sigma}_{w}^{2}$ is the error variance from the between estimator, \n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_{w}^{2} = \\frac{1}{N-K}\\left(\\bar{\\mathbf{y}} - \\mathbf{\\bar{X}}\\hat{\\mathbf{\\beta}}_{BE}\\right)^{\\prime}\\left(\\bar{\\mathbf{y}} - \\mathbf{\\bar{X}}\\hat{\\mathbf{\\beta}}_{BE}\\right),\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\beta}_{BE}$ are the between estimater coefficients. The between-groups estimator is not something we have introduced before, but is attained by regressing the time-averaged outcomes $\\overline{y}_i$ on the time-averaged regressors $\\overline{\\mathbf{x}}_i,i=1,2,\\dotsc,N$.\n",
    "\n",
    "*Note:* There are other procedures for estimating the variances. See Wooldridge p. 294-296 for more details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: The Between Estimator\n",
    "Estimate the between groups model, which is simply the average within each each individual,\n",
    "\n",
    "$$\n",
    "\\bar{y}_{i} = \\boldsymbol{\\bar{x}}_{i}\\boldsymbol{\\beta} + c_i + \\bar{u}_{i}.\n",
    "$$\n",
    "\n",
    "So instead of demeaning, like we did in FE, we just calculate the mean with the following transformation *vector* $\\mathbf{P}_T$,\n",
    "\n",
    "\\begin{equation} \n",
    "\\mathbf{P}_T \\equiv \\left( \\frac{1}{T}, \\frac{1}{T}, ..., \\frac{1}{T} \\right)_{1 \\times T}  \\notag\n",
    "\\end{equation}\n",
    "\n",
    "In order to estimate eq. (3) with the between estimator. You need to perform the following steps:\n",
    "* Create the mean vector `P`.\n",
    "* mean `x` and `y` using the `perm` function and `P`.\n",
    "* Regress `y_mean` on `x_mean`. Note that there are $N$ rows in each, not $NT$. \n",
    "* Print it out in a nice table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between Estimator\n",
      "Dependent variable: log Deflated sales\n",
      "\n",
      "                              Beta      Se    t-values\n",
      "--------------------------  ------  ------  ----------\n",
      "log Employment              0.6856  0.0333     20.5565\n",
      "log Adjusted Capital Stock  0.2778  0.0295      9.4042\n",
      "R² = 0.921\n",
      "σ² = 0.122\n"
     ]
    }
   ],
   "source": [
    "# Transform the data\n",
    "P_T = np.ones(T) /T \n",
    "P_T = P_T.reshape(1,-1)\n",
    "y_mean = lm.perm(P_T, y)\n",
    "x_mean = lm.perm(P_T, x)\n",
    "\n",
    "# Estimate \n",
    "be_result = lm.estimate(y_mean, x_mean, transform='be', T=T)\n",
    "lm.print_table((label_y, label_x), be_result, title=\"Between Estimator\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "You should now have all the error variances that you need to calculate\n",
    "\n",
    "$$\\hat{\\lambda} = 1 - \\sqrt{\\frac{\\widehat{\\sigma}_{u}^{2}}{(\\widehat{\\sigma}_{u}^{2} + T\\widehat{\\sigma}_{c}^{2})}}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda is approximately equal to 0.8509.\n"
     ]
    }
   ],
   "source": [
    "# Calculate lambda (note lambda is a reserved keyword in Python, so we use _lambda instead)\n",
    "sigma2_u = fe_result['sigma2']\n",
    "sigma2_w = be_result['sigma2']\n",
    "sigma2_c = sigma2_w-(1/T)*sigma2_u \n",
    "_lambda = 1-np.sqrt(sigma2_u/(sigma2_u + T*sigma2_c))\n",
    "\n",
    "# Print lambda \n",
    "print(f'Lambda is approximately equal to {_lambda.item():.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Now we are finally ready to estimate eq. (3) with random effects. Since we have to use $\\hat{\\lambda}$ to quasi-demean within each individual, we again use the `perm` function. This time, we pass it the following transformation matrix,\n",
    "\n",
    "$$\n",
    "\\mathbf{C}_{T}:=\\mathbf{I}_{T} - \\hat{\\lambda}\\mathbf{P}_{T},\n",
    "$$\n",
    "\n",
    "where $\\mathbf{P}_{T}$ is the $1 \\times T$ transformation vector we used earlier to calculate the mean of each person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Effects\n",
      "Dependent variable: log Deflated sales\n",
      "\n",
      "                              Beta      Se    t-values\n",
      "--------------------------  ------  ------  ----------\n",
      "log Employment              0.6912  0.0235     29.4669\n",
      "log Adjusted Capital Stock  0.2477  0.0214     11.6004\n",
      "R² = 0.797\n",
      "σ² = 0.008\n",
      "Lambda= [[0.8509242]]\n"
     ]
    }
   ],
   "source": [
    "# Transform the data\n",
    "C_T = np.identity(T) - _lambda*P_T\n",
    "y_re = lm.perm(C_T, y)\n",
    "x_re = lm.perm(C_T, x)\n",
    "\n",
    "# Estimate \n",
    "re_result = lm.estimate(y_re, x_re, transform='re', T=T)\n",
    "lm.print_table((label_y, label_x), re_result, title=\"Random Effects\", floatfmt='.4f')\n",
    "print(\"Lambda=\", _lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short introduction to Hausman test\n",
    "\n",
    "It is evident from the previous question that RE has the advantage over FE that time-invariant variables are not demeaned away. But if $E[c_{i}\\boldsymbol{x}_{it}] \\neq \\boldsymbol{0}$, then the RE estimator is inconsistent, where the FE estimator is consistent (but inefficient), assuming strict exogeneity.\n",
    "\n",
    "We can use the results from the FE and RE estimations to test whether RE is consistent, by calculating the following test statistics,\n",
    "\n",
    "$$\n",
    "H := (\\hat{\\boldsymbol{\\beta}}_{FE} - \\hat{\\boldsymbol{\\beta}}_{RE})'[\\widehat{\\mathrm{avar}}(\\hat{\\boldsymbol{\\beta}}_{FE}) - \\widehat{\\mathrm{avar}}(\\hat{\\mathbf{\\beta}}_{RE})]^{-1}(\\hat{\\boldsymbol{\\beta}}_{FE}-\\hat{\\boldsymbol{\\beta}}_{RE})\\overset{d}{\\to}\\chi_{M}^{2}, \\tag{7}\n",
    "$$\n",
    "where M is the number of time-variant variables included in the test.\n",
    "\n",
    "*Note 1*: The vector $\\hat{\\boldsymbol{\\beta}}_{RE}$ excludes time invariant variables as these are not present in $\\hat{\\boldsymbol{\\beta}}_{FE}$. <br>\n",
    "*Note 2:* $\\widehat{\\mathrm{avar}}(\\hat{\\boldsymbol{\\beta}}_{RE})$ means the RE covariance (but again, we only keep the rows and columns for time-variant variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: Comparing FE and RE\n",
    "Use the results from the FE and RE esimtations to compute the Hausman test statistics in eq. (7).\n",
    "\n",
    "* Start by calculating the differences in the FE and RE coefficients $\\hat{\\boldsymbol{\\beta}}_{FE} - \\hat{\\boldsymbol{\\beta}}_{RE}$ (remember to remove the time invariant variables from RE)\n",
    "* Then calculate the differences in the covariances $\\widehat{\\mathrm{avar}}(\\hat{\\boldsymbol{\\beta}}_{FE}) - \\widehat{\\mathrm{avar}}(\\hat{\\boldsymbol{\\beta}}_{RE})$ (again, remember to remove the time invariant variables for RE estimates)\n",
    "* You now have all the components to compute the Hausman test statistics in eq. (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test statistic is 50.88.\n",
      "The critical value at a 5% significance level is 5.99.\n",
      "The p-value is 0.00000000.\n"
     ]
    }
   ],
   "source": [
    "# Unpack\n",
    "b_fe = fe_result['b_hat'] # Fill in\n",
    "b_re = re_result['b_hat']\n",
    "cov_fe = fe_result['cov']\n",
    "cov_re = re_result['cov'] # Do we have any time invariant variables? Don't think so\n",
    "\n",
    "# Calculate the test statistic\n",
    "b_diff = b_fe - b_re\n",
    "cov_diff = cov_fe - cov_re\n",
    "H = b_diff.T@la.inv(cov_diff)@b_diff\n",
    "\n",
    "# Find critical value and p-value at 5% significance level of chi^2 with M degrees of freedom\n",
    "M = 2\n",
    "crit_val = stats.chi2.ppf(1 - 0.05, df=M)\n",
    "p_val = 1 - stats.chi2.cdf(H.item() , df=M)\n",
    "\n",
    "# Print the results\n",
    "print(f'The test statistic is {H.item():.2f}.')\n",
    "print(f'The critical value at a 5% significance level is {crit_val:.2f}.')\n",
    "print(f'The p-value is {p_val:.8f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which assumption is tested by the Hausman test? What is the null hypothesis? Does the Hausman test you have conducted rely on any other assumptions (See Wooldridge, p. 328-331)? Based on your test result, which estimator would you use to estimate eq. (3)? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "28b1ca885001685b2bc3a39df2ddd10ef1aa60bad7babe65fad257ff6b65d8b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
